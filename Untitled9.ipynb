{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-e6MOqhxlTun",
        "outputId": "22c92393-39df-4e73-d75b-e251cd5d13d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets, utils\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images , train_labels) , (test_images , test_labels) = datasets.cifar10.load_data()\n",
        "train_images , test_images = train_images / 255.0 , test_images / 255.0\n"
      ],
      "metadata": {
        "id": "jV9MmWWcmNad"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape\n",
        "train_labels.shape\n",
        "train_images\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hzJvkG4nyV-z",
        "outputId": "856dbf9d-d52f-4533-b9ed-5f0c36d2afe4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.23137255, 0.24313725, 0.24705882],\n",
              "         [0.16862745, 0.18039216, 0.17647059],\n",
              "         [0.19607843, 0.18823529, 0.16862745],\n",
              "         ...,\n",
              "         [0.61960784, 0.51764706, 0.42352941],\n",
              "         [0.59607843, 0.49019608, 0.4       ],\n",
              "         [0.58039216, 0.48627451, 0.40392157]],\n",
              "\n",
              "        [[0.0627451 , 0.07843137, 0.07843137],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.07058824, 0.03137255, 0.        ],\n",
              "         ...,\n",
              "         [0.48235294, 0.34509804, 0.21568627],\n",
              "         [0.46666667, 0.3254902 , 0.19607843],\n",
              "         [0.47843137, 0.34117647, 0.22352941]],\n",
              "\n",
              "        [[0.09803922, 0.09411765, 0.08235294],\n",
              "         [0.0627451 , 0.02745098, 0.        ],\n",
              "         [0.19215686, 0.10588235, 0.03137255],\n",
              "         ...,\n",
              "         [0.4627451 , 0.32941176, 0.19607843],\n",
              "         [0.47058824, 0.32941176, 0.19607843],\n",
              "         [0.42745098, 0.28627451, 0.16470588]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.81568627, 0.66666667, 0.37647059],\n",
              "         [0.78823529, 0.6       , 0.13333333],\n",
              "         [0.77647059, 0.63137255, 0.10196078],\n",
              "         ...,\n",
              "         [0.62745098, 0.52156863, 0.2745098 ],\n",
              "         [0.21960784, 0.12156863, 0.02745098],\n",
              "         [0.20784314, 0.13333333, 0.07843137]],\n",
              "\n",
              "        [[0.70588235, 0.54509804, 0.37647059],\n",
              "         [0.67843137, 0.48235294, 0.16470588],\n",
              "         [0.72941176, 0.56470588, 0.11764706],\n",
              "         ...,\n",
              "         [0.72156863, 0.58039216, 0.36862745],\n",
              "         [0.38039216, 0.24313725, 0.13333333],\n",
              "         [0.3254902 , 0.20784314, 0.13333333]],\n",
              "\n",
              "        [[0.69411765, 0.56470588, 0.45490196],\n",
              "         [0.65882353, 0.50588235, 0.36862745],\n",
              "         [0.70196078, 0.55686275, 0.34117647],\n",
              "         ...,\n",
              "         [0.84705882, 0.72156863, 0.54901961],\n",
              "         [0.59215686, 0.4627451 , 0.32941176],\n",
              "         [0.48235294, 0.36078431, 0.28235294]]],\n",
              "\n",
              "\n",
              "       [[[0.60392157, 0.69411765, 0.73333333],\n",
              "         [0.49411765, 0.5372549 , 0.53333333],\n",
              "         [0.41176471, 0.40784314, 0.37254902],\n",
              "         ...,\n",
              "         [0.35686275, 0.37254902, 0.27843137],\n",
              "         [0.34117647, 0.35294118, 0.27843137],\n",
              "         [0.30980392, 0.31764706, 0.2745098 ]],\n",
              "\n",
              "        [[0.54901961, 0.62745098, 0.6627451 ],\n",
              "         [0.56862745, 0.6       , 0.60392157],\n",
              "         [0.49019608, 0.49019608, 0.4627451 ],\n",
              "         ...,\n",
              "         [0.37647059, 0.38823529, 0.30588235],\n",
              "         [0.30196078, 0.31372549, 0.24313725],\n",
              "         [0.27843137, 0.28627451, 0.23921569]],\n",
              "\n",
              "        [[0.54901961, 0.60784314, 0.64313725],\n",
              "         [0.54509804, 0.57254902, 0.58431373],\n",
              "         [0.45098039, 0.45098039, 0.43921569],\n",
              "         ...,\n",
              "         [0.30980392, 0.32156863, 0.25098039],\n",
              "         [0.26666667, 0.2745098 , 0.21568627],\n",
              "         [0.2627451 , 0.27058824, 0.21568627]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.68627451, 0.65490196, 0.65098039],\n",
              "         [0.61176471, 0.60392157, 0.62745098],\n",
              "         [0.60392157, 0.62745098, 0.66666667],\n",
              "         ...,\n",
              "         [0.16470588, 0.13333333, 0.14117647],\n",
              "         [0.23921569, 0.20784314, 0.22352941],\n",
              "         [0.36470588, 0.3254902 , 0.35686275]],\n",
              "\n",
              "        [[0.64705882, 0.60392157, 0.50196078],\n",
              "         [0.61176471, 0.59607843, 0.50980392],\n",
              "         [0.62352941, 0.63137255, 0.55686275],\n",
              "         ...,\n",
              "         [0.40392157, 0.36470588, 0.37647059],\n",
              "         [0.48235294, 0.44705882, 0.47058824],\n",
              "         [0.51372549, 0.4745098 , 0.51372549]],\n",
              "\n",
              "        [[0.63921569, 0.58039216, 0.47058824],\n",
              "         [0.61960784, 0.58039216, 0.47843137],\n",
              "         [0.63921569, 0.61176471, 0.52156863],\n",
              "         ...,\n",
              "         [0.56078431, 0.52156863, 0.54509804],\n",
              "         [0.56078431, 0.5254902 , 0.55686275],\n",
              "         [0.56078431, 0.52156863, 0.56470588]]],\n",
              "\n",
              "\n",
              "       [[[1.        , 1.        , 1.        ],\n",
              "         [0.99215686, 0.99215686, 0.99215686],\n",
              "         [0.99215686, 0.99215686, 0.99215686],\n",
              "         ...,\n",
              "         [0.99215686, 0.99215686, 0.99215686],\n",
              "         [0.99215686, 0.99215686, 0.99215686],\n",
              "         [0.99215686, 0.99215686, 0.99215686]],\n",
              "\n",
              "        [[1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ]],\n",
              "\n",
              "        [[1.        , 1.        , 1.        ],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         ...,\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.44313725, 0.47058824, 0.43921569],\n",
              "         [0.43529412, 0.4627451 , 0.43529412],\n",
              "         [0.41176471, 0.43921569, 0.41568627],\n",
              "         ...,\n",
              "         [0.28235294, 0.31764706, 0.31372549],\n",
              "         [0.28235294, 0.31372549, 0.30980392],\n",
              "         [0.28235294, 0.31372549, 0.30980392]],\n",
              "\n",
              "        [[0.43529412, 0.4627451 , 0.43137255],\n",
              "         [0.40784314, 0.43529412, 0.40784314],\n",
              "         [0.38823529, 0.41568627, 0.38431373],\n",
              "         ...,\n",
              "         [0.26666667, 0.29411765, 0.28627451],\n",
              "         [0.2745098 , 0.29803922, 0.29411765],\n",
              "         [0.30588235, 0.32941176, 0.32156863]],\n",
              "\n",
              "        [[0.41568627, 0.44313725, 0.41176471],\n",
              "         [0.38823529, 0.41568627, 0.38431373],\n",
              "         [0.37254902, 0.4       , 0.36862745],\n",
              "         ...,\n",
              "         [0.30588235, 0.33333333, 0.3254902 ],\n",
              "         [0.30980392, 0.33333333, 0.3254902 ],\n",
              "         [0.31372549, 0.3372549 , 0.32941176]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.1372549 , 0.69803922, 0.92156863],\n",
              "         [0.15686275, 0.69019608, 0.9372549 ],\n",
              "         [0.16470588, 0.69019608, 0.94509804],\n",
              "         ...,\n",
              "         [0.38823529, 0.69411765, 0.85882353],\n",
              "         [0.30980392, 0.57647059, 0.77254902],\n",
              "         [0.34901961, 0.58039216, 0.74117647]],\n",
              "\n",
              "        [[0.22352941, 0.71372549, 0.91764706],\n",
              "         [0.17254902, 0.72156863, 0.98039216],\n",
              "         [0.19607843, 0.71764706, 0.94117647],\n",
              "         ...,\n",
              "         [0.61176471, 0.71372549, 0.78431373],\n",
              "         [0.55294118, 0.69411765, 0.80784314],\n",
              "         [0.45490196, 0.58431373, 0.68627451]],\n",
              "\n",
              "        [[0.38431373, 0.77254902, 0.92941176],\n",
              "         [0.25098039, 0.74117647, 0.98823529],\n",
              "         [0.27058824, 0.75294118, 0.96078431],\n",
              "         ...,\n",
              "         [0.7372549 , 0.76470588, 0.80784314],\n",
              "         [0.46666667, 0.52941176, 0.57647059],\n",
              "         [0.23921569, 0.30980392, 0.35294118]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.28627451, 0.30980392, 0.30196078],\n",
              "         [0.20784314, 0.24705882, 0.26666667],\n",
              "         [0.21176471, 0.26666667, 0.31372549],\n",
              "         ...,\n",
              "         [0.06666667, 0.15686275, 0.25098039],\n",
              "         [0.08235294, 0.14117647, 0.2       ],\n",
              "         [0.12941176, 0.18823529, 0.19215686]],\n",
              "\n",
              "        [[0.23921569, 0.26666667, 0.29411765],\n",
              "         [0.21568627, 0.2745098 , 0.3372549 ],\n",
              "         [0.22352941, 0.30980392, 0.40392157],\n",
              "         ...,\n",
              "         [0.09411765, 0.18823529, 0.28235294],\n",
              "         [0.06666667, 0.1372549 , 0.20784314],\n",
              "         [0.02745098, 0.09019608, 0.1254902 ]],\n",
              "\n",
              "        [[0.17254902, 0.21960784, 0.28627451],\n",
              "         [0.18039216, 0.25882353, 0.34509804],\n",
              "         [0.19215686, 0.30196078, 0.41176471],\n",
              "         ...,\n",
              "         [0.10588235, 0.20392157, 0.30196078],\n",
              "         [0.08235294, 0.16862745, 0.25882353],\n",
              "         [0.04705882, 0.12156863, 0.19607843]]],\n",
              "\n",
              "\n",
              "       [[[0.74117647, 0.82745098, 0.94117647],\n",
              "         [0.72941176, 0.81568627, 0.9254902 ],\n",
              "         [0.7254902 , 0.81176471, 0.92156863],\n",
              "         ...,\n",
              "         [0.68627451, 0.76470588, 0.87843137],\n",
              "         [0.6745098 , 0.76078431, 0.87058824],\n",
              "         [0.6627451 , 0.76078431, 0.8627451 ]],\n",
              "\n",
              "        [[0.76078431, 0.82352941, 0.9372549 ],\n",
              "         [0.74901961, 0.81176471, 0.9254902 ],\n",
              "         [0.74509804, 0.80784314, 0.92156863],\n",
              "         ...,\n",
              "         [0.67843137, 0.75294118, 0.8627451 ],\n",
              "         [0.67058824, 0.74901961, 0.85490196],\n",
              "         [0.65490196, 0.74509804, 0.84705882]],\n",
              "\n",
              "        [[0.81568627, 0.85882353, 0.95686275],\n",
              "         [0.80392157, 0.84705882, 0.94117647],\n",
              "         [0.8       , 0.84313725, 0.9372549 ],\n",
              "         ...,\n",
              "         [0.68627451, 0.74901961, 0.85098039],\n",
              "         [0.6745098 , 0.74509804, 0.84705882],\n",
              "         [0.6627451 , 0.74901961, 0.84313725]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.81176471, 0.78039216, 0.70980392],\n",
              "         [0.79607843, 0.76470588, 0.68627451],\n",
              "         [0.79607843, 0.76862745, 0.67843137],\n",
              "         ...,\n",
              "         [0.52941176, 0.51764706, 0.49803922],\n",
              "         [0.63529412, 0.61960784, 0.58823529],\n",
              "         [0.65882353, 0.63921569, 0.59215686]],\n",
              "\n",
              "        [[0.77647059, 0.74509804, 0.66666667],\n",
              "         [0.74117647, 0.70980392, 0.62352941],\n",
              "         [0.70588235, 0.6745098 , 0.57647059],\n",
              "         ...,\n",
              "         [0.69803922, 0.67058824, 0.62745098],\n",
              "         [0.68627451, 0.6627451 , 0.61176471],\n",
              "         [0.68627451, 0.6627451 , 0.60392157]],\n",
              "\n",
              "        [[0.77647059, 0.74117647, 0.67843137],\n",
              "         [0.74117647, 0.70980392, 0.63529412],\n",
              "         [0.69803922, 0.66666667, 0.58431373],\n",
              "         ...,\n",
              "         [0.76470588, 0.72156863, 0.6627451 ],\n",
              "         [0.76862745, 0.74117647, 0.67058824],\n",
              "         [0.76470588, 0.74509804, 0.67058824]]],\n",
              "\n",
              "\n",
              "       [[[0.89803922, 0.89803922, 0.9372549 ],\n",
              "         [0.9254902 , 0.92941176, 0.96862745],\n",
              "         [0.91764706, 0.9254902 , 0.96862745],\n",
              "         ...,\n",
              "         [0.85098039, 0.85882353, 0.91372549],\n",
              "         [0.86666667, 0.8745098 , 0.91764706],\n",
              "         [0.87058824, 0.8745098 , 0.91372549]],\n",
              "\n",
              "        [[0.87058824, 0.86666667, 0.89803922],\n",
              "         [0.9372549 , 0.9372549 , 0.97647059],\n",
              "         [0.91372549, 0.91764706, 0.96470588],\n",
              "         ...,\n",
              "         [0.8745098 , 0.8745098 , 0.9254902 ],\n",
              "         [0.89019608, 0.89411765, 0.93333333],\n",
              "         [0.82352941, 0.82745098, 0.8627451 ]],\n",
              "\n",
              "        [[0.83529412, 0.80784314, 0.82745098],\n",
              "         [0.91764706, 0.90980392, 0.9372549 ],\n",
              "         [0.90588235, 0.91372549, 0.95686275],\n",
              "         ...,\n",
              "         [0.8627451 , 0.8627451 , 0.90980392],\n",
              "         [0.8627451 , 0.85882353, 0.90980392],\n",
              "         [0.79215686, 0.79607843, 0.84313725]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.58823529, 0.56078431, 0.52941176],\n",
              "         [0.54901961, 0.52941176, 0.49803922],\n",
              "         [0.51764706, 0.49803922, 0.47058824],\n",
              "         ...,\n",
              "         [0.87843137, 0.87058824, 0.85490196],\n",
              "         [0.90196078, 0.89411765, 0.88235294],\n",
              "         [0.94509804, 0.94509804, 0.93333333]],\n",
              "\n",
              "        [[0.5372549 , 0.51764706, 0.49411765],\n",
              "         [0.50980392, 0.49803922, 0.47058824],\n",
              "         [0.49019608, 0.4745098 , 0.45098039],\n",
              "         ...,\n",
              "         [0.70980392, 0.70588235, 0.69803922],\n",
              "         [0.79215686, 0.78823529, 0.77647059],\n",
              "         [0.83137255, 0.82745098, 0.81176471]],\n",
              "\n",
              "        [[0.47843137, 0.46666667, 0.44705882],\n",
              "         [0.4627451 , 0.45490196, 0.43137255],\n",
              "         [0.47058824, 0.45490196, 0.43529412],\n",
              "         ...,\n",
              "         [0.70196078, 0.69411765, 0.67843137],\n",
              "         [0.64313725, 0.64313725, 0.63529412],\n",
              "         [0.63921569, 0.63921569, 0.63137255]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_INDEX = 49999  # change this to look at other images\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "# plt.figure()\n",
        "# plt.imshow(train_images[IMG_INDEX] ,cmap=plt.cm.binary)\n",
        "# plt.xlabel(class_names[train_labels[IMG_INDEX][0]])\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "SyDALwNen60T"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=models.Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64,activation='relu'))\n",
        "model.add(layers.Dense(10))"
      ],
      "metadata": {
        "id": "m-tKEr0jyFbN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b96c8264-1dac-4b03-998b-711b37f94172"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='Adamax',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "92x2h9Hh0K9k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_images, train_labels, epochs=8,\n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "44fdX8jy0Rue",
        "outputId": "cac97bbf-f4a7-48d7-d762-3b43bfdadc92"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 50ms/step - accuracy: 0.2960 - loss: 1.9035 - val_accuracy: 0.4797 - val_loss: 1.4424\n",
            "Epoch 2/8\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 49ms/step - accuracy: 0.4959 - loss: 1.4019 - val_accuracy: 0.5503 - val_loss: 1.2601\n",
            "Epoch 3/8\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 49ms/step - accuracy: 0.5630 - loss: 1.2375 - val_accuracy: 0.5844 - val_loss: 1.1680\n",
            "Epoch 4/8\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 48ms/step - accuracy: 0.6024 - loss: 1.1251 - val_accuracy: 0.6275 - val_loss: 1.0573\n",
            "Epoch 5/8\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 49ms/step - accuracy: 0.6402 - loss: 1.0282 - val_accuracy: 0.6449 - val_loss: 1.0034\n",
            "Epoch 6/8\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 48ms/step - accuracy: 0.6645 - loss: 0.9615 - val_accuracy: 0.6597 - val_loss: 0.9715\n",
            "Epoch 7/8\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 53ms/step - accuracy: 0.6834 - loss: 0.9120 - val_accuracy: 0.6621 - val_loss: 0.9543\n",
            "Epoch 8/8\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 49ms/step - accuracy: 0.7029 - loss: 0.8637 - val_accuracy: 0.6945 - val_loss: 0.8860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_images,  test_labels, verbose=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "571ViEr81Ccq",
        "outputId": "95194c94-9fe7-4e58-c819-2c7766fcf44b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8859587907791138, 0.6945000290870667]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "utQCfoyz8DBz",
        "outputId": "d9d8172b-baa0-4424-cdba-bfaf56fdcd66"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6],\n",
              "       [9],\n",
              "       [9],\n",
              "       ...,\n",
              "       [9],\n",
              "       [1],\n",
              "       [1]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "img_path = '/test_image.jpg'  # Provide the path to your image here\n",
        "img = image.load_img(img_path, target_size=(32, 32))\n",
        "\n",
        "# Step 2: Convert the image to a numpy array\n",
        "img_array = image.img_to_array(img)\n",
        "\n",
        "# Step 3: Normalize the image\n",
        "img_array = img_array / 255.0  # Scaling the image to be between 0 and 1\n",
        "\n",
        "# Step 4: Expand dimensions to match the model's input shape\n",
        "img_array = np.expand_dims(img_array, axis=0)  # (1, 32, 32, 3)\n",
        "\n",
        "# The image is now ready for model evaluation\n",
        "# Step 5: Evaluate the model on this single image\n",
        "predictions = model.predict(img_array)\n",
        "\n",
        "# Optional: Print the predictions\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zAxeNSsX612V",
        "outputId": "735f439c-07bc-4ab9-9576-7b00ad87b8d0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
            "[[ 5.626914   -0.32364175  0.75023305 -2.6693144  -6.802434   -6.196869\n",
            "  -2.8286593  -7.92513     4.421582   -1.6097699 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_index = np.argmax(predictions[0])\n",
        "\n",
        "# Access the class name using the predicted index\n",
        "print(class_names[predicted_class_index])"
      ],
      "metadata": {
        "id": "Uaj3mc2l8YjG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "dc688d2b-bf98-42e5-9b93-f346ed207116"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "airplane\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # Correct the import statement\n",
        "\n",
        "datagen = ImageDataGenerator( # Correct the typo\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode = 'nearest'\n",
        ")\n",
        "# test_img = train_images[20]\n",
        "# img = image.img_to_array(test_img)  # convert image to numpy arry\n",
        "# img = img.reshape((1,) + img.shape)  # reshape image\n",
        "# plt.figure()\n",
        "# img.shape\n",
        "augmented_images = []\n",
        "augmented_labels = []\n",
        "\n",
        "for i in range(len(train_images)):\n",
        "  img = image.img_to_array(train_images[i])\n",
        "  img = img.reshape((1,) + img.shape)\n",
        "  if i< len(train_labels):\n",
        "    label = class_names[train_labels[i][0]]\n",
        "\n",
        "  # Generate augmented images for each image in the training set\n",
        "  for batch in datagen.flow(img, batch_size=1, save_prefix='test', save_format='jpeg'): # Reduced batch size to 1 to augment each image individually\n",
        "      augmented_images.append(batch[0])\n",
        "      augmented_labels.append(label)\n",
        "      break # Generate only one augmented image per original image\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "gllC0Cqsj0xW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Convert the lists to NumPy arrays\n",
        "augmented_images = np.array(augmented_images)\n",
        "augmented_labels_numeric = np.array([class_names.index(label) for label in augmented_labels]).reshape(-1, 1)\n",
        "\n",
        "# Append the augmented data to the training set\n",
        "train_images = np.concatenate((train_images, augmented_images))\n",
        "train_labels = np.concatenate((train_labels, augmented_labels_numeric))"
      ],
      "metadata": {
        "id": "QoUj9mtsn8iJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "id": "UQaihw9cqMUX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4ea551a5-7d7b-4d3d-c981-00898c4852df"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2=models.Sequential()\n",
        "model2.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3)))\n",
        "model2.add(layers.MaxPooling2D((2,2)))\n",
        "model2.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
        "model2.add(layers.MaxPooling2D((2,2)))\n",
        "model2.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
        "model2.add(layers.Flatten())\n",
        "model2.add(layers.Dense(64,activation='relu'))\n",
        "model2.add(layers.Dense(10))\n",
        "model2.compile(\n",
        "    optimizer='Adamax',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy']\n",
        ")\n",
        "history2 = model2.fit(train_images, train_labels, epochs=8,\n",
        "                    validation_data=(test_images, test_labels))\n",
        "model2.evaluate(test_images,  test_labels, verbose = 0.01)"
      ],
      "metadata": {
        "id": "Yvwo-nLGG74Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a5497e9c-e474-4a32-9584-65caef686319"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 47ms/step - accuracy: 0.3026 - loss: 1.8815 - val_accuracy: 0.4842 - val_loss: 1.4177\n",
            "Epoch 2/8\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 48ms/step - accuracy: 0.4778 - loss: 1.4607 - val_accuracy: 0.5959 - val_loss: 1.1744\n",
            "Epoch 3/8\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 47ms/step - accuracy: 0.5366 - loss: 1.3080 - val_accuracy: 0.6370 - val_loss: 1.0579\n",
            "Epoch 4/8\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 48ms/step - accuracy: 0.5664 - loss: 1.2228 - val_accuracy: 0.6196 - val_loss: 1.0871\n",
            "Epoch 5/8\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 48ms/step - accuracy: 0.5969 - loss: 1.1460 - val_accuracy: 0.6790 - val_loss: 0.9267\n",
            "Epoch 6/8\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 48ms/step - accuracy: 0.6166 - loss: 1.0852 - val_accuracy: 0.6821 - val_loss: 0.9079\n",
            "Epoch 7/8\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 48ms/step - accuracy: 0.6367 - loss: 1.0311 - val_accuracy: 0.6960 - val_loss: 0.8807\n",
            "Epoch 8/8\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 47ms/step - accuracy: 0.6554 - loss: 0.9828 - val_accuracy: 0.7121 - val_loss: 0.8399\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8398774266242981, 0.7121000289916992]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}